setwd("~/TDDE01/lab2")
####Task 1####
data = read.csv("creditscoring.csv", header=TRUE, sep=";", dec=",")
n=dim(data)[1]
set.seed(12345)
id=sample(1:n, floor(n*0.5))
training=data[id,]
temp=data[-id,]
n2=dim(temp)[1]
id2=sample(1:n2, floor(n2*0.5))
validation=temp[id2,]
test=temp[-id2,]
####Task 2####
library(tree)
fit_dev <- tree(good_bad~.,data=training, split="deviance")
fit_gin <- tree(good_bad~.,data=training, split="gini")
pred_dev_test <- predict(fit_dev, test, type="class")
pred_gin_test <- predict(fit_gin, test, type="class")
targets_test <- test[,dim(test)[2]]
tab_dev <- table(pred_dev_test,targets_test)
mcr_dev <- 1-sum(diag(tab_dev))/sum(tab_dev)
tab_gin <- table(pred_gin_test, targets_test)
mcr_gin <- 1-sum(diag(tab_gin))/sum(tab_dev)
print (list(DEV=mcr_dev,GINI=mcr_gin))
id=sample(1:n, floor(n*0.5))
training=data[id,]
temp=data[-id,]
n2=dim(temp)[1]
id2=sample(1:n2, floor(n2*0.5))
validation=temp[id2,]
test=temp[-id2,]
####Task 2####
library(tree)
fit_dev <- tree(good_bad~.,data=training, split="deviance")
fit_gin <- tree(good_bad~.,data=training, split="gini")
pred_dev_test <- predict(fit_dev, test, type="class")
pred_gin_test <- predict(fit_gin, test, type="class")
#targets_test <- test[,dim(test)[2]]
targets_test <- test$good_bad
tab_dev <- table(pred_dev_test,targets_test)
mcr_dev <- 1-sum(diag(tab_dev))/sum(tab_dev)
tab_gin <- table(pred_gin_test, targets_test)
mcr_gin <- 1-sum(diag(tab_gin))/sum(tab_dev)
print (list(DEV=mcr_dev,GINI=mcr_gin))
####Task 1####
data = read.csv("creditscoring.csv", header=TRUE, sep=";", dec=",")
n=dim(data)[1]
set.seed(12345)
id=sample(1:n, floor(n*0.5))
training=data[id,]
temp=data[-id,]
n2=dim(temp)[1]
id2=sample(1:n2, floor(n2*0.5))
validation=temp[id2,]
test=temp[-id2,]
####Task 2####
library(tree)
fit_dev <- tree(good_bad~.,data=training, split="deviance")
fit_gin <- tree(good_bad~.,data=training, split="gini")
pred_dev_test <- predict(fit_dev, test, type="class")
pred_gin_test <- predict(fit_gin, test, type="class")
#targets_test <- test[,dim(test)[2]]
targets_test <- test$good_bad
tab_dev <- table(pred_dev_test,targets_test)
mcr_dev <- 1-sum(diag(tab_dev))/sum(tab_dev)
tab_gin <- table(pred_gin_test, targets_test)
mcr_gin <- 1-sum(diag(tab_gin))/sum(tab_dev)
print (list(DEV=mcr_dev,GINI=mcr_gin))
####Task 1####
data = read.csv("creditscoring.csv", header=TRUE, sep=";", dec=",")
n=dim(data)[1]
set.seed(12345)
id=sample(1:n, floor(n*0.5))
training=data[id,]
temp=data[-id,]
n2=dim(temp)[1]
id2=sample(1:n2, floor(n2*0.5))
validation=temp[id2,]
test=temp[-id2,]
####Task 2####
library(tree)
fit_dev <- tree(good_bad~.,data=training, split="deviance")
fit_gin <- tree(good_bad~.,data=training, split="gini")
pred_dev_test <- predict(fit_dev, test, type="class")
pred_gin_test <- predict(fit_gin, test, type="class")
targets_test <- test[,dim(test)[2]]
#targets_test <- test$good_bad
tab_dev <- table(pred_dev_test,targets_test)
mcr_dev <- 1-sum(diag(tab_dev))/sum(tab_dev)
tab_gin <- table(pred_gin_test, targets_test)
mcr_gin <- 1-sum(diag(tab_gin))/sum(tab_dev)
print (list(DEV=mcr_dev,GINI=mcr_gin))
####Task 1####
data = read.csv("creditscoring.csv", header=TRUE, sep=";", dec=",")
n=dim(data)[1]
set.seed(12345)
id=sample(1:n, floor(n*0.5))
training=data[id,]
temp=data[-id,]
n2=dim(temp)[1]
id2=sample(1:n2, floor(n2*0.5))
validation=temp[id2,]
test=temp[-id2,]
####Task 2####
library(tree)
fit_dev <- tree(good_bad~.,data=training, split="deviance")
fit_gin <- tree(good_bad~.,data=training, split="gini")
pred_dev_train <- predict(fit_dev, training, type="class")
pred_gin_train <- predict(fit_gin, training, type="class")
targets_train <- training$good_bad
pred_dev_test <- predict(fit_dev, test, type="class")
pred_gin_test <- predict(fit_gin, test, type="class")
targets_test <- test$good_bad
summary(fit_dev)
####Task 1####
data = read.csv("creditscoring.csv", header=TRUE, sep=";", dec=",")
n=dim(data)[1]
set.seed(12345)
id=sample(1:n, floor(n*0.5))
training=data[id,]
temp=data[-id,]
n2=dim(temp)[1]
id2=sample(1:n2, floor(n2*0.5))
validation=temp[id2,]
test=temp[-id2,]
####Task 2####
library(tree)
fit_dev <- tree(good_bad~.,data=training, split="deviance")
fit_gin <- tree(good_bad~.,data=training, split="gini")
training_fit_dev <- summary(fit_dev)
training_fit_gin <- summary(fit_gin)
print(list(DEV=training_fit_dev$misclass, GINI=training_fit_gin$misclass))
training_fit_dev
train_mcr_dev <- summary(fit_dev)$misclass[1]/ summary(fit_dev)$misclass[2]
####Task 1####
data = read.csv("creditscoring.csv", header=TRUE, sep=";", dec=",")
n=dim(data)[1]
set.seed(12345)
id=sample(1:n, floor(n*0.5))
training=data[id,]
temp=data[-id,]
n2=dim(temp)[1]
id2=sample(1:n2, floor(n2*0.5))
validation=temp[id2,]
test=temp[-id2,]
####Task 2####
library(tree)
fit_dev <- tree(good_bad~.,data=training, split="deviance")
fit_gin <- tree(good_bad~.,data=training, split="gini")
train_mcr_dev <- summary(fit_dev)$misclass[1]/ summary(fit_dev)$misclass[2]
train_mcr_gin <- summary(fit_gin)$misclass[1]/summary(fit_gin)$misclass[2]
print(list(DEV=train_mcr_dev, GINI=train_mcr_gin))
pred_dev_test <- predict(fit_dev, test, type="class")
pred_gin_test <- predict(fit_gin, test, type="class")
targets_test <- test$good_bad
tab_dev <- table(pred_dev_test,targets_test)
mcr_dev <- 1-sum(diag(tab_dev))/sum(tab_dev)
tab_gin <- table(pred_gin_test, targets_test)
mcr_gin <- 1-sum(diag(tab_gin))/sum(tab_dev)
print (list(DEV=mcr_dev,GINI=mcr_gin))
####Step 3####
trainScore=rep(0,9)
validScore=rep(0,9)
nodes=seq(2,9,1)
for (i in 1:length(nodes)+1){
prunedTree <- prune.tree(fit_dev, best=i)
pred <- predict(prunedTree, newdata=validation, type="tree")
trainScore[i] = deviance(prunedTree)
validScore[i] = deviance(pred)
}
plot(2:9, trainScore[2:9], type="b", col="red", ylim=c(0,800))
points(2:9, validScore[2:9], type="b", col="blue")
minScore_valid <- which.min(validScore[2:9])
optimalLeaves <- nodes[minScore_valid]
finalTree <- prune.tree(fit_dev, best=optimalLeaves)
print(finalTree)
predict_test <- predict(finalTree, newdata = test, type="class")
tab2 <- table(predict_test, targets_test)
mcr2 <- 1-sum(diag(tab2))/sum(tab2)
print(list(TAB=tab2, MCR=mcr2))
trainScore=rep(0,9)
validScore=rep(0,9)
nodes=seq(2,9,1)
for (i in 1:length(nodes)+1){
prunedTree <- prune.tree(fit_dev, best=i)
pred <- predict(prunedTree, newdata=validation, type="tree")
trainScore[i] = deviance(prunedTree)
validScore[i] = deviance(pred)
}
plot(2:9, trainScore[2:9], type="b", col="red", ylim=c(0,800))
points(2:9, validScore[2:9], type="b", col="blue")
minScore_valid <- which.min(validScore[2:9])
optimalLeaves <- nodes[minScore_valid]
finalTree <- prune.tree(fit_dev, best=optimalLeaves)
print(finalTree)
predict_test <- predict(finalTree, newdata = test, type="class")
tab2 <- table(predict_test, targets_test)
mcr2 <- 1-sum(diag(tab2))/sum(tab2)
print(list(TAB=tab2, MCR=mcr2))
####Step 4####
library(MASS)
library(e1071)
fit_nb <- naiveBayes(good_bad~., data = training)
Yfit_train <- predict(fit_nb, newdata = training)
tab_train <- table(Yfit_train, training$good_bad)
mcr_train <- 1-sum(diag(tab_train))/sum(tab_train)
print (list(TABLE=tab_train, MCR=mcr_train))
Yfit_test <- predict(fit_nb, newdata = test)
tab_test <- table(Yfit_test, test$good_bad)
mcr_test <- 1-sum(diag(tab_test))/sum(tab_test)
print (list(TABLE=tab_test, MCR=mcr_test))
install.packages("e1071")
trainScore=rep(0,9)
validScore=rep(0,9)
nodes=seq(2,9,1)
for (i in 1:length(nodes)+1){
prunedTree <- prune.tree(fit_dev, best=i)
pred <- predict(prunedTree, newdata=validation, type="tree")
trainScore[i] = deviance(prunedTree)
validScore[i] = deviance(pred)
}
plot(2:9, trainScore[2:9], type="b", col="red", ylim=c(0,800))
points(2:9, validScore[2:9], type="b", col="blue")
minScore_valid <- which.min(validScore[2:9])
optimalLeaves <- nodes[minScore_valid]
finalTree <- prune.tree(fit_dev, best=optimalLeaves)
print(finalTree)
predict_test <- predict(finalTree, newdata = test, type="class")
tab2 <- table(predict_test, targets_test)
mcr2 <- 1-sum(diag(tab2))/sum(tab2)
print(list(TAB=tab2, MCR=mcr2))
####Step 4####
library(MASS)
library(e1071)
fit_nb <- naiveBayes(good_bad~., data = training)
Yfit_train <- predict(fit_nb, newdata = training)
tab_train <- table(Yfit_train, training$good_bad)
mcr_train <- 1-sum(diag(tab_train))/sum(tab_train)
print (list(TABLE=tab_train, MCR=mcr_train))
Yfit_test <- predict(fit_nb, newdata = test)
tab_test <- table(Yfit_test, test$good_bad)
mcr_test <- 1-sum(diag(tab_test))/sum(tab_test)
print (list(TABLE=tab_test, MCR=mcr_test))
####Task 1####
data = read.csv("creditscoring.csv", header=TRUE, sep=";", dec=",")
n=dim(data)[1]
set.seed(12345)
id=sample(1:n, floor(n*0.5))
training=data[id,]
temp=data[-id,]
n2=dim(temp)[1]
id2=sample(1:n2, floor(n2*0.5))
validation=temp[id2,]
test=temp[-id2,]
####Task 2####
library(tree)
fit_dev <- tree(good_bad~.,data=training, split="deviance")
fit_gin <- tree(good_bad~.,data=training, split="gini")
train_mcr_dev <- summary(fit_dev)$misclass[1]/ summary(fit_dev)$misclass[2]
train_mcr_gin <- summary(fit_gin)$misclass[1]/summary(fit_gin)$misclass[2]
print(list(DEV=train_mcr_dev, GINI=train_mcr_gin))
pred_dev_test <- predict(fit_dev, test, type="class")
pred_gin_test <- predict(fit_gin, test, type="class")
targets_test <- test$good_bad
tab_dev <- table(pred_dev_test,targets_test)
mcr_dev <- 1-sum(diag(tab_dev))/sum(tab_dev)
tab_gin <- table(pred_gin_test, targets_test)
mcr_gin <- 1-sum(diag(tab_gin))/sum(tab_dev)
print (list(DEV=mcr_dev,GINI=mcr_gin))
####Task 3####
trainScore=rep(0,9)
validScore=rep(0,9)
nodes=seq(2,9,1)
for (i in 1:length(nodes)+1){
prunedTree <- prune.tree(fit_dev, best=i)
pred <- predict(prunedTree, newdata=validation, type="tree")
trainScore[i] = deviance(prunedTree)
validScore[i] = deviance(pred)
}
plot(2:9, trainScore[2:9]/2, type="b", col="red", ylim=c(0,800))
points(2:9, validScore[2:9], type="b", col="blue")
plot(2:9, trainScore[2:9]/2, type="b", col="red", ylim=c(200,400))
points(2:9, validScore[2:9], type="b", col="blue")
plot(2:9, trainScore[2:9]/2, type="b", col="red", ylim=c(250,350))
points(2:9, validScore[2:9], type="b", col="blue")
plot(2:9, trainScore[2:9]/2, type="b", col="red", ylim=c(250,310))
points(2:9, validScore[2:9], type="b", col="blue")
plot(2:9, trainScore[2:9]/2, type="b", col="red", ylim=c(250,300))
points(2:9, validScore[2:9], type="b", col="blue")
####Task 1####
data = read.csv("creditscoring.csv", header=TRUE, sep=";", dec=",")
n=dim(data)[1]
set.seed(12345)
id=sample(1:n, floor(n*0.5))
training=data[id,]
temp=data[-id,]
n2=dim(temp)[1]
id2=sample(1:n2, floor(n2*0.5))
validation=temp[id2,]
test=temp[-id2,]
####Task 2####
library(tree)
fit_dev <- tree(good_bad~.,data=training, split="deviance")
fit_gin <- tree(good_bad~.,data=training, split="gini")
train_mcr_dev <- summary(fit_dev)$misclass[1]/ summary(fit_dev)$misclass[2]
train_mcr_gin <- summary(fit_gin)$misclass[1]/summary(fit_gin)$misclass[2]
print(list(DEV=train_mcr_dev, GINI=train_mcr_gin))
pred_dev_test <- predict(fit_dev, test, type="class")
pred_gin_test <- predict(fit_gin, test, type="class")
targets_test <- test$good_bad
tab_dev <- table(pred_dev_test,targets_test)
mcr_dev <- 1-sum(diag(tab_dev))/sum(tab_dev)
tab_gin <- table(pred_gin_test, targets_test)
mcr_gin <- 1-sum(diag(tab_gin))/sum(tab_dev)
print (list(DEV=mcr_dev,GINI=mcr_gin))
####Task 3####
trainScore=rep(0,9)
validScore=rep(0,9)
nodes=seq(2,9,1)
for (i in 1:length(nodes)+1){
prunedTree <- prune.tree(fit_dev, best=i)
pred <- predict(prunedTree, newdata=validation, type="tree")
trainScore[i] = deviance(prunedTree)
validScore[i] = deviance(pred)
}
plot(2:9, trainScore[2:9]/2, type="b", col="red", ylim=c(250,300))
points(2:9, validScore[2:9], type="b", col="blue")
minScore_valid <- which.min(validScore[2:9])
optimalLeaves <- nodes[minScore_valid]
finalTree <- prune.tree(fit_dev, best=optimalLeaves)
print(finalTree)
print(finalTree)
plot(finalTree)
text(finalTree, pretty=0)
predict_test <- predict(finalTree, newdata = test, type="class")
tab2 <- table(predict_test, targets_test)
mcr2 <- 1-sum(diag(tab2))/sum(tab2)
print(list(TAB=tab2, MCR=mcr2))
####Task 4####
library(MASS)
library(e1071)
fit_nb <- naiveBayes(good_bad~., data = training)
Yfit_train <- predict(fit_nb, newdata = training)
tab_train <- table(Yfit_train, training$good_bad)
mcr_train <- 1-sum(diag(tab_train))/sum(tab_train)
print (list(TABLE=tab_train, MCR=mcr_train))
Yfit_test <- predict(fit_nb, newdata = test)
tab_test <- table(Yfit_test, test$good_bad)
mcr_test <- 1-sum(diag(tab_test))/sum(tab_test)
print (list(TABLE=tab_test, MCR=mcr_test))
spectra = read.csv("NIRSpectra.csv", header=TRUE, sep=";", dec=",")
set.seed(12345)
####Task 1####
data1 = spectra
data1$Viscosity = c()
res = prcomp(data1)
lambda = res$sdev^2
lambda #eigenvalues
sprintf("%2.3f", lambda/sum(lambda)*100)
screeplot(res)
plot(res$x[,1], res$x[,2])
#yes, some outliers
?prcomp
####Task 2####
U = res$rotation
plot(U[,1], main="traceplot, PC1")
plot(U[,2], main="traceplot, PC2")
# only last 10 (index 110-120) explains PC2 well
set.seed(12345)
library(fastICA)
a = fastICA(data1, n.comp=2, alg.typ= "parallel", fun="logcosh", alpha=1, method="R", row.norm=FALSE, maxit=200, tol=0.0001, verbose=TRUE)
Wtic = a$K%*%a$W
plot(Wtic[,1], main="traceplot column 1")
plot(Wtic[,2], main="traceplot column 2")
# K is loading from oridinal to PCA space, loadings in Wtic is how much in original data is loaded into the ICAroom
plot(a$S)
?fastICA
library(pls)
set.seed(12345)
pcr_model = pcr(Viscosity~., data=spectra, scale=TRUE, validation="CV")
summary(pcr_model)
validationplot(pcr_model, val.type="RMSEP")
which.min(pcr_model$validation$PRESS)
####Task 4####
library(pls)
set.seed(12345)
pcr_model = pcr(Viscosity~., data=spectra, scale=TRUE, validation="CV")
summary(pcr_model)
validationplot(pcr_model, val.type="RMSEP") #root mean squared error
which.min(pcr_model$validation$PRESS)
data = read.csv("State.csv", header=TRUE, sep=";", dec=",")
set.seed(12345)
####Step 1####
ordered_data<- data[order(data$MET),]
plot(ordered_data$MET, ordered_data$EX)
#
library(tree)
nobs=dim(ordered_data)[1]
control <- tree.control(nobs=nobs, minsize=8)
fit <- tree(EX~MET, data=ordered_data, control=control)
Yfit <- predict(fit, newdata = ordered_data)
points(ordered_data$MET, Yfit, col="red")
fit.sum <- summary(fit)
hist(fit.sum$residuals)
data = read.csv("State.csv", header=TRUE, sep=";", dec=",")
set.seed(12345)
####Step 1####
ordered_data<- data[order(data$MET),]
plot(ordered_data$MET, ordered_data$EX)
####Step 2####
library(tree)
nobs=dim(ordered_data)[1]
control <- tree.control(nobs=nobs, minsize=8)
fit <- tree(EX~MET, data=ordered_data, control=control)
Yfit <- predict(fit, newdata = ordered_data)
points(ordered_data$MET, Yfit, col="red")
fit.sum <- summary(fit)
hist(fit.sum$residuals)
#targets <- ordered_data[,"EX"]
#residuals <- Yfit - targets
#hist(residuals)
####Step 3####
library(boot)
#computing bootstrap samples
f = function(data, ind) {
D <- data[ind,]
res <- tree(EX~MET, data=D, control=control)
pred <- predict(res, newdata=ordered_data)
return(pred)
}
res <- boot(ordered_data, f, R=1000)
#compute confidence bands
e <- envelope(res)
plot(ordered_data$MET, ordered_data$EX)
lines(ordered_data$MET, Yfit, col="red")
lines(ordered_data$MET, e$point[2,], col="blue")
lines(ordered_data$MET, e$point[1,], col="green")
####Step 4####
rng = function(data, mle) {
D = data.frame(MET=data$MET, EX=data$EX)
n = length(data$EX)
#Generate new EX
D$EX = rnorm(n, predict(mle, newdata=D), mle$residuals)
return(D)
}
f4 = function(D){
res = tree(EX~MET, data=D) #fit tree model
#predict values for all MET values from the original data
EXpred = predict(res, newdata=ordered_data)
return(EXpred)
}
res4 = boot(ordered_data, statistic=f4, R=1000, mle=fit, ran.gen=rng, sim="parametric")
